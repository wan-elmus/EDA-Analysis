<!doctype html>
<html>
<head>
<meta charset="UTF-8">
	
<link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet" type="text/css"> 
<link href="/shared/Regis_CSS/CCIS/acb.css" rel="stylesheet" type="text/css" media="screen"> 
<link href="/shared/Regis_CSS/print.css" rel="stylesheet" type="text/css" media="print">
<title>MSDS600</title>
</head>

<body>
<h1>From the Expert: Decision Tree ML and Feature Selection</h1>
<p><span style="color: #002b5c;">Tree-based machine learning is widely used and important to know. Random forests, XGBoost, and other tree-based methods often perform best for ML tasks. The presentation (slides in the week 4 content) covers some of the foundational concepts:</span></p>
<p><span style="color: #002b5c;"><iframe width="560" height="315" src="https://www.youtube.com/embed/jOszpXo2lfM?wmode=opaque&amp;rel=0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></span></p>
<p>Tree-based ML methods are easy to use with sklearn, and the interface is the same as logistic regression we saw last week. We can also easily plot the feature importances. The FTE Jupyter Notebook covers&nbsp; these topics for the week, with an overview here:</p>
<p><iframe width="560" height="315" src="https://www.youtube.com/embed/BYnpqTXTPzk?wmode=opaque&amp;rel=0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<p></p>
</body>
</html>