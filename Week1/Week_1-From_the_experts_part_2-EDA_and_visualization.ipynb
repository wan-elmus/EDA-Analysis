{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "nominated-benefit",
   "metadata": {},
   "source": [
    "# CRISP-DM for prediction of diabetes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expressed-sitting",
   "metadata": {},
   "source": [
    "Over the next few weeks, we'll go through a simple example of a data science process:\n",
    "\n",
    "- business understanding (asking the right questions)\n",
    "- loading data\n",
    "- EDA (exploratory data analysis), visualization\n",
    "- data cleaning and preparation\n",
    "- modeling and evaluation\n",
    "- communication of results\n",
    "    \n",
    "In this file, we'll cover the first three bullets above.\n",
    "    \n",
    "# 1. Business understanding\n",
    "\n",
    "In this demo, we'll be working with a dataset with health and biographic data on diabetes diagoneses from [here](https://data.world/informatics-edu/diabetes-prediction). The purpose of our task is to understand which data is related to the occurance of diabetes, and to eventually predict a risk of diabetes based on the data. Our question is: can we accurately predict the occurance of diabetes based on the demographic and medical data we collect? With this, we can offer better personalized health services to people, and potentially improve the overall health of everyone by understanding what we can do to reduce the risk of diabetes.\n",
    "\n",
    "We'll start with EDA (exploratory data analysis) - both numeric and visual."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perceived-observation",
   "metadata": {},
   "source": [
    "# 2. Data understanding - EDA and visualization basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sensitive-piano",
   "metadata": {},
   "source": [
    "Understanding how to create charts and plots of data is an important first step in understanding the data. In this first section, we'll cover the bare bones basics which are all you need to complete the assignments this week."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-people",
   "metadata": {},
   "source": [
    "Make sure you've got the following packages installed before starting. You can install them from a terminal or command prompt with `conda install -c conda-forge pandas pandas-profiling matplotlib openpyxl`, or you can install them in a jupyter cell with `!conda install -c conda-forge pandas pandas-profiling matplotlib openpyxl -y`. If conda is taking too long, you can use pip instead: `!pip install pandas-profiling`. Press shift+enter to run the cells after selecting them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blessed-farming",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -c conda-forge pandas matplotlib openpyxl -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-coaching",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faced-watershed",
   "metadata": {},
   "source": [
    "First, we load the data. `pandas` is one of the most, if not *the* most, common data loading and preparation package in Python for data science. The documentation is excellent for the package, and it can read from many filetypes. Here is the page for the `read_excel` function: https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html\n",
    "\n",
    "The main class in pandas is the DataFrame, which is often stored in a variable `df`. If you are getting an error, you may need to install `openpyxl` as shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sticky-operator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can give an index number or name for our index column, or leave it blank\n",
    "df = pd.read_excel('data/diabetes_data.xlsx', index_col='Patient number')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neural-press",
   "metadata": {},
   "source": [
    "It's always a good idea to look at the top and bottom of the data to make sure everything looks ok. We can see printing out the `df` object in jupyter (by putting the df object as the last line in the cell) prints the top and bottom of the data. We can also do this with `head` and `tail`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpful-trustee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impaired-skill",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parental-pennsylvania",
   "metadata": {},
   "source": [
    "## Using pandas for EDA and visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "partial-system",
   "metadata": {},
   "source": [
    "The pandas package has a few functions for generating numeric EDA and statistics, and can easily plot data.\n",
    "\n",
    "numeric EDA:\n",
    "- info\n",
    "- describe\n",
    "- unique\n",
    "- value_counts\n",
    "\n",
    "plots:\n",
    "- bar plots\n",
    "- histograms\n",
    "- scatter plots\n",
    "\n",
    "other:\n",
    "- filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-collar",
   "metadata": {},
   "source": [
    "### Numeric EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romance-bible",
   "metadata": {},
   "source": [
    "Info shows the datatypes (dtype), number of values, and number of missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "renewable-cyprus",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "musical-affiliation",
   "metadata": {},
   "source": [
    "Describe shows some numeric stats on numeric columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-consent",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appointed-prefix",
   "metadata": {},
   "source": [
    "We can get the columns like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "particular-leeds",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "written-cooper",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a column\n",
    "df['Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daily-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a column and get the counts of each unique value\n",
    "df['Age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consistent-chair",
   "metadata": {},
   "outputs": [],
   "source": [
    "# similar, but only gets unique values\n",
    "df['Age'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-legend",
   "metadata": {},
   "source": [
    "### Bar plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-white",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn value_counts into a bar plot\n",
    "df['Age'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affiliated-province",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can make it easier to read by restricting the number of values to the top 10\n",
    "df['Age'].value_counts()[:10].plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cheap-marshall",
   "metadata": {},
   "source": [
    "This is using the matplotlib package, so we can add axes labels and other things to the plot with matplotlib. The matlpotlib package is one of (if not *the*) oldest plotting packages in Python. For most common things, we can search the internet for it (e.g. add x-axis label) and we will usually arrive at a stack overflow page or the matplotlib documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mathematical-roulette",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df['Age'].value_counts()[:10].plot.bar()\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heard-installation",
   "metadata": {},
   "source": [
    "If you want to hide the printout of text, assign the last line to the _ variable (essentially, throw away the output that gets printed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "average-likelihood",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'].value_counts()[:10].plot.bar()\n",
    "plt.xlabel('Age')\n",
    "_ = plt.ylabel('Counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "northern-boating",
   "metadata": {},
   "source": [
    "If you want to share the figure, you can right click it and copy or save the image, or you can see the example at the bottom of the notebook for saving a figure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valuable-pendant",
   "metadata": {},
   "source": [
    "### Histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geological-hughes",
   "metadata": {},
   "source": [
    "Three common types of plots we can use are bar plots (like we saw), histograms, and scatter plots. Histograms are generated by pandas-profiling, but we can also look at a particular histogram like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enabling-geology",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Glucose'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-artwork",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this slightly different interface has a different style and generally looks better without gridlines\n",
    "df['Glucose'].plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "located-inventory",
   "metadata": {},
   "source": [
    "There are many options for the function shown in the docs:\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.hist.html\n",
    "\n",
    "Here, we change the number of bars (bins)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tropical-stability",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Glucose'].plot.hist(bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "essential-analyst",
   "metadata": {},
   "source": [
    "### Scatter plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "economic-construction",
   "metadata": {},
   "source": [
    "Scatter plots are for showing the relationship between two continuous variables, or variables that can take any value within a given range (e.g. both glucose and cholesterol can be any value above 0, but cholesterol is usually in the range 100-300)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-subscriber",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.scatter(x='Cholesterol', y='Glucose')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filled-spectacular",
   "metadata": {},
   "source": [
    "# Optional - Advanced EDA and visualization\n",
    "This part is not required, but is extra for those who want to learn more. It covers:\n",
    "- filtering dataframes\n",
    "- plotting with seaborn\n",
    "- using the phik correlation\n",
    "- time series plots with pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "through-handling",
   "metadata": {},
   "source": [
    "### Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alike-correspondence",
   "metadata": {},
   "source": [
    "If we want to get only certain subsets of the data, we can filter it. For example, let's get everyone over the median age. It's usually best to use copy() at the end to take a copy of the slice of the dataframe -- this avoids the settingwithcopy errors that can happen otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "played-haven",
   "metadata": {},
   "outputs": [],
   "source": [
    "over_median_age = df[df['Age'] > df['Age'].median()].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-alias",
   "metadata": {},
   "source": [
    "This uses a boolean comparison, which indexes the dataframe and returns rows where the condition is `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tired-provider",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'] > df['Age'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepted-novel",
   "metadata": {},
   "source": [
    "We can use the same boolean comparison operators as in most of Python and other programming, such as <, >, <=, >=, ==, and !=. We can also negate something with the ~ character:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "express-genealogy",
   "metadata": {},
   "outputs": [],
   "source": [
    "~(df['Age'] > df['Age'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grateful-defense",
   "metadata": {},
   "source": [
    "To combine filters, we use the & (and) and | (or) operators, and be careful to wrap each conditional filter within parentheses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compatible-raising",
   "metadata": {},
   "outputs": [],
   "source": [
    "over_median_age_chol = df[(df['Age'] > df['Age'].median()) & (df['Cholesterol'] > df['Cholesterol'].median())].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-australian",
   "metadata": {},
   "outputs": [],
   "source": [
    "over_median_age_chol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "after-peripheral",
   "metadata": {},
   "source": [
    "We can filter to get the two groups of diabetes and no diabetes people, and then look at the proportions of the genders in the groups (since the numbers in the groups are not the same). The `shape` attribute of a dataframe is a tuple with (rows, columns), so getting the first element with `[0]` gives us the number of rows. It looks like there isn't a large difference in the balance of male/female genders between these two groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocal-toilet",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unavailable-gazette",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df = df[df['Diabetes'] == 'Diabetes']\n",
    "\n",
    "diabetes_df['Gender'].value_counts() / diabetes_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "color-matthew",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_diabetes_df = df[df['Diabetes'] == 'No diabetes']\n",
    "\n",
    "no_diabetes_df['Gender'].value_counts() / no_diabetes_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extensive-fishing",
   "metadata": {},
   "source": [
    "This is also what the `normalize` argument does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "speaking-bible",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "no_diabetes_df['Gender'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "searching-tenant",
   "metadata": {},
   "source": [
    "## Seaborn for plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moderate-islam",
   "metadata": {},
   "source": [
    "seaborn is a package that uses matplotlib and pandas dataframes to create more complex plots with minimal effort. In our case, we can group our data by people with and without diabetes, and plot some of their characterists. We are also going to use the phik package for correlations, so we need to install both these packages first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parliamentary-cover",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -c conda-forge seaborn phik -y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innocent-prospect",
   "metadata": {},
   "source": [
    "Setting `stat='density'` and `common_norm=True` normalizes area under the individual histograms so they equal 1.\n",
    "This makes it easier to compare the two groups. We can see that people with diabetes tend to have much higher glucose levels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fallen-radar",
   "metadata": {},
   "outputs": [],
   "source": [
    "import phik\n",
    "import seaborn as sns\n",
    "\n",
    "_ = sns.histplot(data=df, y='Glucose', hue='Diabetes', stat='density', common_norm=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "little-boating",
   "metadata": {},
   "source": [
    "With seaborn, we can create scatter plots and color them by groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indoor-commons",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(data=df, x='Cholesterol', y='Glucose', hue='Diabetes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romantic-petroleum",
   "metadata": {},
   "source": [
    "One other nice plot to examine is a correlogram. This shows the linear correlations between columns. We can see the pairs BMI and weight as well as waist and hip measurements are strongly correlated with each other. This is the Pearson correlation, which shows linear relationships between two numeric columns. For more advanced correlations, try the Phi-k correlation package: https://phik.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "terminal-functionality",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-raising",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.phik_matrix())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-speech",
   "metadata": {},
   "source": [
    "One last note: the `countplot` in seaborn is very much like doing `df['column'].value_counts().plot.bar()`, but allows us to use the `hue` argument to group data by a categorical variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "second-requirement",
   "metadata": {},
   "source": [
    "## Time series plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "placed-extraction",
   "metadata": {},
   "source": [
    "Time series plots are a little different, since we'll often be using the x-axis as sequential time. With pandas, as long as our timestamp is a timestamp datatype and our dataframe index, we can easily plot timeseries data. We'll be using data from here: https://www.kaggle.com/selfishgene/historical-hourly-weather-data?select=temperature.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-tract",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df = pd.read_csv('data/temperature.csv', index_col='datetime', parse_dates=['datetime'], infer_datetime_format=True)\n",
    "time_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premium-cedar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see the index is of type \"DatetimeIndex\"\n",
    "time_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loaded-conflict",
   "metadata": {},
   "source": [
    "We could also get our data in a proper format using `pd.to_datetime()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "announced-folks",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df2 = pd.read_csv('data/temperature.csv')\n",
    "time_df2['datetime'] = pd.to_datetime(time_df2['datetime'])\n",
    "time_df2.set_index('datetime', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personalized-harassment",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-parker",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df['Denver'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stretch-bumper",
   "metadata": {},
   "source": [
    "One last trick we'll learn with datetime data is we can *resample* it, meaning change the time increments. We can convert our data to monthly data like so. We need to provide a transformation for the data, like 'mean' to take the average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-change",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df_months = time_df.resample('1M').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "related-handy",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df_months['Denver'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "variable-drive",
   "metadata": {},
   "source": [
    "If you want to remove missing values, dropna works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-machine",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capable-vegetarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df.dropna(inplace=True)\n",
    "time_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuffed-warning",
   "metadata": {},
   "source": [
    "### Saving a plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foster-fields",
   "metadata": {},
   "source": [
    "Saving a plot allows you to get higher resolution and control the size of the plot. In general, we want to first create the figure object with our specified size, then create our figure, then use plt.tight_layout, then save the figure. Remember `plt` is matplotlib which we imported earlier. Here is a respectable figure showing the temperature in Denver over the years. `dpi` is dots per inch. A higher value means higher resolution and bigger filesize. 300 can work well.\n",
    "\n",
    "Notice we also convert the units from Kelvin to Farenheight and add reasonable x- and y-labels so that the plot is easily understood. Making a good plot requires this effort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-merit",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df_months['Denver_F'] = 9 / 5 * (time_df_months['Denver'] - 273) + 32\n",
    "\n",
    "f = plt.figure(figsize=(5.5, 5.5))\n",
    "time_df_months['Denver_F'].plot()\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Temperature (F)')\n",
    "plt.tight_layout()  # auto-adjust margins\n",
    "plt.savefig('denver_temps.jpg', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automatic-shuttle",
   "metadata": {},
   "source": [
    "## Further resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "downtown-thickness",
   "metadata": {},
   "source": [
    "The pandas documentation is excellent and shows how to create plots: https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html\n",
    "\n",
    "Seaborn also has a gallery with examples: https://seaborn.pydata.org/examples/index.html\n",
    "\n",
    "Kaggle has a short course on Python visualization: https://www.kaggle.com/learn/overview"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
